---
title: Prompt Engineering 101
description: 提示工程（或者上下文提示），是指如何与LLM进行交流，从而引导大模型输出我们期望得到的结果
date: '2024-12-12'
---

> 这篇文章更多是自己从其他资源中提炼的知识，遵循二八法则，只提炼那些可以解决80%问题的20%知识。


提示工程（上下文提示），用人话说，就是如何与LLM进行交流，从而引导大模型输出我们期望得到的结果。

因为每个模型存在差异，同一个提示词构造方法构造出的提示，对于不同的模型，效果可能差异很大，所以怎么构造Prompt（提示），就成了一个比较吃经验的活儿。

所以才出现了提示词工程的概念，甚至专业的提示词工程师职位。

> BTW，常用的提示词构造方法有一些基本的范式，本身并不复杂，不要被Prompt Engineering的名号吓到 🤷‍♂️。核心的工作在于不断地调整与测试，找到那个让当前LLM效果最好的Prompt。

##  Basic Prompting（基础提示）

### Zero-Shot（零样本提示）

直白的说，就是不加任何技巧，直接问你感兴趣的问题

比如：
```
Q: 
历史上最伟大的科学家是谁，只需要名字就行，不用介绍他们的信息

A: 
艾萨克·牛顿（Isaac Newton）
```

> 当然，我们在这个问题的末尾，加上了我们的要求，要不然它给的就是下面看起来比较啰嗦的答案

```
Q: 
历史上最伟大的科学家是谁

A: 
历史上有许多伟大的科学家，他们在不同的领域做出了重要贡献，因此很难单独指出一位作为“最伟大”的科学家。不过，有几位科学家因其杰出的成就而广受认可：

1. **艾萨克·牛顿（Isaac Newton）**：牛顿的贡献主要在物理学和数学领域。他的经典力学奠定了现代物理学的基础，《自然哲学的数学原理》是科学史上的里程碑。他还与莱布尼茨共同发展了微积分。

2. **阿尔伯特·爱因斯坦（Albert Einstein）**：爱因斯坦因其狭义和广义相对论而闻名，彻底改变了我们对时间、空间和重力的理解。他的质能方程 \(E=mc^2\) 是现代物理学的核心概念之一。

3. **玛丽·居里（Marie Curie）**：居里是研究放射性的重要人物，因其在放射性元素镭和钋的研究中取得的成就而两次获得诺贝尔奖，是首位获得诺贝尔奖的女性。

4. **查尔斯·达尔文（Charles Darwin）**：达尔文以其进化论和自然选择理论而著称，他的著作《物种起源》深刻影响了生物学的发展。

5. **伽利略·伽利莱（Galileo Galilei）**：伽利略在天文学、物理学和科学方法论方面做出了开创性贡献，被誉为“现代科学之父”。

这些科学家在各自的时代和领域中都引领了科学的重大进步，对人类知识的扩展产生了深远的影响。
```

> LLM的工作原理是自回归输出，也就是它会根据前面的内容来预测下一个输出，直到需要闭嘴为止。所以它通常来说是比较啰嗦的。我们需要给他尽可能多准确的要求，也就是下达的指令要清晰。

### Few-shot（少量样本提示）

零样本提示，对于一般的、对答案要求不高的场景来说，基本上是够用的，通常大部分日常化的问题是够用了。

但是，对于一些稍微复杂一点的场景可能就会没那么令我们满意了，我们需要给出一些样例，让它更能理解我们需要它做什么，就像我们让一个小孩子帮我们做事情，我们需要给他举一些例子，让他更清晰的理解我们的意图。

比如：
```
Q: 
文本：小明在舞台上到处跳跃，跳舞、奔跑、流汗、擦脸，总之展现了最初让他成名的古怪才华。 
情感：积极

文本：尽管所有证据都相反，这部失败之作不知怎么地假装成了一部真正的电影，那种收取全额票价、在电视上大肆宣传并声称能娱乐小孩和所谓成年人的电影。 
情感：消极

文本：多年来，小明第一次在情感上深入挖掘，可能是因为他被他合演明星的强大作品所打动。 
情感：积极

文本：我敢打赌，电子游戏比电影有趣得多。 
情感：

A: 消极

```

>  我们给了三个样例，以及他们的情感分类（消极、积极），这样LLM就更能理解我们自己的意图。

但是，任何方案都不是万能的。

因为我们提供了样例，所以Few-shot会消耗更多的token，也就以为着需要更多的💰。

还有一个比较容易忽视的问题是，对于类似标签分类的场景，每个类别的样例需要提供数量近似的例子，免得LLM有失偏颇，产生偏见。

> 如果示例中的标签分布不均衡，LLM可能倾向于多数标签。而且LLM可能倾向于重复最后一个标签。
> 
> 所以，需要提供尽可能多样性、均衡的例子和标签，例子和标签的关联性要准确。例子的顺序可以随机打散，避免LLM倾向于后一种例子标签。


## Instruction Prompting（指令提示）

> 上面我们大概介绍了Few-shot，其实从Few-shot的构造方法来看，我们之所以告诉LLM很多例子，无非是因为我们希望LLM能够理解我们的意图，每个例子其实就相当于对指令（意图）的说明，如果想要让LLM完全理解我们的指令（意图）就需要给很多例子进行说明。
> 
> 但是，这样就会增加很多的上下文输入，我们可以想象一下，跟一个小学生啰嗦过多该怎么做怎么做的例子，其实他也记不住，LLM也是这样的，这就是LLM的上下文长度限制。

既然这样，我们不如训练LLM，让LLM理解人类的指令（意图），直接告诉他我们的指令就行了。类似于成年人肯定比孩子更能理解简单的指令（意图）。

于是，就有了通过RHLF进行训练的 Instructed LLM，具体怎么把LLM训练的能理解人类的指令，不是本文的重点，我们只需要知道，目前市面上的LLM基本上都能理解常规的指令就足够了。

比如：我们可以直接告诉LLM，需要它为我们做什么
```
Q：
请为给定的电影评论标记对电影的情感态度。情感标签应为“积极”或“消极”。  
文本：我敢打赌，这款电子游戏比电影有趣得多。  
情感：

A：
情感：消极
```

*我们可能会在社交媒体上看到很多博主教我们怎么构造Prompt，甚至可以出一本书，基本上都是基于Instruction Prompt的思想*

你甚至可以把Instruction Prompt和Few-shot结合起来，来更好的引导LLM给出更准确的输出。

## Chain-of-Thought (CoT) （思维链）

一般来说，掌握 Basic Prompting 和 Instruction Prompting 已经能满足日常的场景需求了。

但是，当我们需要一些更复杂的推理场景时，就需要更加符合人类思考负责问题的方式了。这就是CoT的思路，模拟人类的推理过程，通过一系列连贯的逻辑推导系统性地解决问题。

> CoT 提示不仅仅是生成连贯且相关的响应，还要求 AI 从头开始构建完整的逻辑论证，包括前提和结论。

比如，如果 AI 被问到“天空是什么颜色的？”，AI 会生成一个简单直接的回答，例如“天空是蓝色的。” 然而，如果使用 CoT 提示要求 AI 解释为什么天空是蓝色的，AI 首先会定义“蓝色”的含义（即一种原色），然后推导出天空之所以呈现蓝色，是因为大气吸收了其他颜色。这一回答体现了 AI 构建逻辑论证的能力。

更复杂的问题，比如：

```
Q:
马蒂有100厘米的缎带，他需要将其切成4等份。每份都必须再分成5等份。每段最后的长度是多少？ 
让我们一步一步地来思考答案。

A:
好的，让我们按照步骤来解决这个问题：

第一步：将100厘米的缎带切成4等份
每份的长度 = 100厘米 ÷ 4 = 25厘米

第二步：将每份再分成5等份
每份再分成5等份后，每小段的长度 = 25厘米 ÷ 5 = 5厘米

结论
每段最后的长度是 5 厘米

希望这个步骤-by-步骤的解答对您有帮助！如果您有任何其他问题，请随时告诉我。
```

### CoT 类型

#### Few-shot CoT（少样本 CoT）

Few-shot CoT 通过给模型一些用思维推理得出最终结果的例子，提示模型该怎么进行逻辑推理：

```
Q:
问题：汤姆和伊丽莎白进行了一场爬山比赛。伊丽莎白花了30分钟爬上山。汤姆花了伊丽莎白爬山时间的四倍。汤姆爬上山需要多长时间？
答案：汤姆爬上山花了30*4 = 120分钟。
汤姆爬上山花了120/60 = 2小时。
所以答案是2。
---
问题：杰克是一名足球运动员。他需要购买两双袜子和一双足球鞋。每双袜子的价格是9.50美元，鞋子的价格是92美元。杰克有40美元。杰克还需要多少钱？
答案：两双袜子的总费用是9.50 x 2 = 19美元。
袜子和鞋子的总费用是19 + 92 = 111美元。
杰克还需要111 - 40 = 71美元。
因此答案是71。
---
问题：马蒂有100厘米长的丝带，他必须将其切成4等分。每个切割部分必须再分成5等分。每个最终切割的长度将是多少？  
答案：

A:
每个最终切割的长度是5厘米。
```


#### Zero-shot CoT（零样本 CoT）

Zero-shot CoT 就是我们不给模型例子，而是通过一些语句来提示模型要一步步推导出答案：

```
Q:
问题：马蒂有100厘米长的丝带，他必须将其切成4等分。每个切割部分必须再分成5等分。每个最终切割的长度将是多少？  
让我们逐步思考，推导出最终答案。

A:
首先，我们知道马蒂有一根长为100厘米的丝带。他需要将这根丝带切成4等分，这意味着每个部分的长度将是100厘米 ÷ 4 = 25厘米。

接下来，每个这4个部分都需要再切成5等分。因此，我们需要将每个25厘米的部分再切成5等分。这样，每个最终切割的长度将是 25厘米 ÷ 5 = 5厘米。

因此，最终每个切割的长度为5厘米。
```

Zero-shot CoT 和 Few-shot CoT 我们需要根据场景去选择，如果Few-shot CoT 在样本准确的情况下，推理结果肯定会更准确，但也会消耗更多的token💰；Zero-shot CoT 准确性会稍弱，但可以显著减少token💰消耗。
